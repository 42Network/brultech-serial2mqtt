"""
This type stub file was generated by pyright.
"""

import dataclasses
from collections.abc import Callable, Iterable
from datetime import datetime
from statistics import mean
from typing import Any, Literal, TYPE_CHECKING, TypedDict
from sqlalchemy.engine.row import Row
from sqlalchemy.orm.session import Session
from homeassistant.core import HomeAssistant, callback
from homeassistant.helpers.singleton import singleton
from homeassistant.helpers.typing import UndefinedType
from homeassistant.util.unit_conversion import BaseUnitConverter
from .db_schema import StatisticsBase
from .models import StatisticData, StatisticMetaData, StatisticResult
from .util import retryable_database_job
from . import Recorder

"""Statistics helper."""
if TYPE_CHECKING:
    ...
QUERY_STATISTICS = ...
QUERY_STATISTICS_SHORT_TERM = ...
QUERY_STATISTICS_SUMMARY_MEAN = ...
QUERY_STATISTICS_SUMMARY_SUM = ...
STATISTIC_UNIT_TO_UNIT_CONVERTER: dict[str | None, type[BaseUnitConverter]] = ...
DATA_SHORT_TERM_STATISTICS_RUN_CACHE = ...
_LOGGER = ...
@dataclasses.dataclass(slots=True)
class ShortTermStatisticsRunCache:
    """Cache for short term statistics runs."""
    _latest_id_by_metadata_id: dict[int, int] = ...
    def get_latest_ids(self, metadata_ids: set[int]) -> dict[int, int]:
        """Return the latest short term statistics ids for the metadata_ids."""
        ...
    
    def set_latest_id_for_metadata_id(self, metadata_id: int, id_: int) -> None:
        """Cache the latest id for the metadata_id."""
        ...
    
    def set_latest_ids_for_metadata_ids(self, metadata_id_to_id: dict[int, int]) -> None:
        """Cache the latest id for the each metadata_id."""
        ...
    


class BaseStatisticsRow(TypedDict, total=False):
    """A processed row of statistic data."""
    start: float
    ...


class StatisticsRow(BaseStatisticsRow, total=False):
    """A processed row of statistic data."""
    end: float
    last_reset: float | None
    state: float | None
    sum: float | None
    min: float | None
    max: float | None
    mean: float | None
    change: float | None
    ...


def get_display_unit(hass: HomeAssistant, statistic_id: str, statistic_unit: str | None) -> str | None:
    """Return the unit which the statistic will be displayed in."""
    ...

def can_convert_units(from_unit: str | None, to_unit: str | None) -> bool:
    """Return True if it's possible to convert from from_unit to to_unit."""
    ...

@dataclasses.dataclass
class PlatformCompiledStatistics:
    """Compiled Statistics from a platform."""
    platform_stats: list[StatisticResult]
    current_metadata: dict[str, tuple[int, StatisticMetaData]]
    ...


def split_statistic_id(entity_id: str) -> list[str]:
    """Split a state entity ID into domain and object ID."""
    ...

VALID_STATISTIC_ID = ...
def valid_statistic_id(statistic_id: str) -> bool:
    """Test if a statistic ID is a valid format.

    Format: <domain>:<statistic> where both are slugs.
    """
    ...

def validate_statistic_id(value: str) -> str:
    """Validate statistic ID."""
    ...

@dataclasses.dataclass
class ValidationIssue:
    """Error or warning message."""
    type: str
    data: dict[str, str | None] | None = ...
    def as_dict(self) -> dict:
        """Return dictionary version."""
        ...
    


def get_start_time() -> datetime:
    """Return start time."""
    ...

@retryable_database_job("compile missing statistics")
def compile_missing_statistics(instance: Recorder) -> bool:
    """Compile missing statistics."""
    ...

@retryable_database_job("compile statistics")
def compile_statistics(instance: Recorder, start: datetime, fire_events: bool) -> bool:
    """Compile 5-minute statistics for all integrations with a recorder platform.

    The actual calculation is delegated to the platforms.
    """
    ...

def get_metadata_with_session(instance: Recorder, session: Session, *, statistic_ids: set[str] | None = ..., statistic_type: Literal["mean"] | Literal["sum"] | None = ..., statistic_source: str | None = ...) -> dict[str, tuple[int, StatisticMetaData]]:
    """Fetch meta data.

    Returns a dict of (metadata_id, StatisticMetaData) tuples indexed by statistic_id.
    If statistic_ids is given, fetch metadata only for the listed statistics_ids.
    If statistic_type is given, fetch metadata only for statistic_ids supporting it.
    """
    ...

def get_metadata(hass: HomeAssistant, *, statistic_ids: set[str] | None = ..., statistic_type: Literal["mean"] | Literal["sum"] | None = ..., statistic_source: str | None = ...) -> dict[str, tuple[int, StatisticMetaData]]:
    """Return metadata for statistic_ids."""
    ...

def clear_statistics(instance: Recorder, statistic_ids: list[str]) -> None:
    """Clear statistics for a list of statistic_ids."""
    ...

def update_statistics_metadata(instance: Recorder, statistic_id: str, new_statistic_id: str | None | UndefinedType, new_unit_of_measurement: str | None | UndefinedType) -> None:
    """Update statistics metadata for a statistic_id."""
    ...

async def async_list_statistic_ids(hass: HomeAssistant, statistic_ids: set[str] | None = ..., statistic_type: Literal["mean"] | Literal["sum"] | None = ...) -> list[dict]:
    """Return all statistic_ids (or filtered one) and unit of measurement.

    Queries the database for existing statistic_ids, as well as integrations with
    a recorder platform for statistic_ids which will be added in the next statistics
    period.
    """
    ...

def list_statistic_ids(hass: HomeAssistant, statistic_ids: set[str] | None = ..., statistic_type: Literal["mean"] | Literal["sum"] | None = ...) -> list[dict]:
    """Return all statistic_ids (or filtered one) and unit of measurement.

    Queries the database for existing statistic_ids, as well as integrations with
    a recorder platform for statistic_ids which will be added in the next statistics
    period.
    """
    ...

def reduce_day_ts_factory() -> tuple[Callable[[float, float], bool], Callable[[float], tuple[float, float]],]:
    """Return functions to match same day and day start end."""
    ...

def reduce_week_ts_factory() -> tuple[Callable[[float, float], bool], Callable[[float], tuple[float, float]],]:
    """Return functions to match same week and week start end."""
    ...

def reduce_month_ts_factory() -> tuple[Callable[[float, float], bool], Callable[[float], tuple[float, float]],]:
    """Return functions to match same month and month start end."""
    ...

def statistic_during_period(hass: HomeAssistant, start_time: datetime | None, end_time: datetime | None, statistic_id: str, types: set[Literal["max", "mean", "min", "change"]] | None, units: dict[str, str] | None) -> dict[str, Any]:
    """Return a statistic data point for the UTC period start_time - end_time."""
    ...

_type_column_mapping = ...
def statistics_during_period(hass: HomeAssistant, start_time: datetime, end_time: datetime | None, statistic_ids: set[str] | None, period: Literal["5minute", "day", "hour", "week", "month"], units: dict[str, str] | None, types: set[Literal["change", "last_reset", "max", "mean", "min", "state", "sum"]]) -> dict[str, list[StatisticsRow]]:
    """Return statistic data points during UTC period start_time - end_time.

    If end_time is omitted, returns statistics newer than or equal to start_time.
    If statistic_ids is omitted, returns statistics for all statistics ids.
    """
    ...

def get_last_statistics(hass: HomeAssistant, number_of_stats: int, statistic_id: str, convert_units: bool, types: set[Literal["last_reset", "max", "mean", "min", "state", "sum"]]) -> dict[str, list[StatisticsRow]]:
    """Return the last number_of_stats statistics for a statistic_id."""
    ...

def get_last_short_term_statistics(hass: HomeAssistant, number_of_stats: int, statistic_id: str, convert_units: bool, types: set[Literal["last_reset", "max", "mean", "min", "state", "sum"]]) -> dict[str, list[StatisticsRow]]:
    """Return the last number_of_stats short term statistics for a statistic_id."""
    ...

def get_latest_short_term_statistics_by_ids(session: Session, ids: Iterable[int]) -> list[Row]:
    """Return the latest short term statistics for a list of ids."""
    ...

def get_latest_short_term_statistics_with_session(hass: HomeAssistant, session: Session, statistic_ids: set[str], types: set[Literal["last_reset", "max", "mean", "min", "state", "sum"]], metadata: dict[str, tuple[int, StatisticMetaData]] | None = ...) -> dict[str, list[StatisticsRow]]:
    """Return the latest short term statistics for a list of statistic_ids with a session."""
    ...

def validate_statistics(hass: HomeAssistant) -> dict[str, list[ValidationIssue]]:
    """Validate statistics."""
    ...

@callback
def async_import_statistics(hass: HomeAssistant, metadata: StatisticMetaData, statistics: Iterable[StatisticData]) -> None:
    """Import hourly statistics from an internal source.

    This inserts an import_statistics job in the recorder's queue.
    """
    ...

@callback
def async_add_external_statistics(hass: HomeAssistant, metadata: StatisticMetaData, statistics: Iterable[StatisticData]) -> None:
    """Add hourly statistics from an external source.

    This inserts an import_statistics job in the recorder's queue.
    """
    ...

@singleton(DATA_SHORT_TERM_STATISTICS_RUN_CACHE)
def get_short_term_statistics_run_cache(hass: HomeAssistant) -> ShortTermStatisticsRunCache:
    """Get the short term statistics run cache."""
    ...

def cache_latest_short_term_statistic_id_for_metadata_id(run_cache: ShortTermStatisticsRunCache, session: Session, metadata_id: int) -> int | None:
    """Cache the latest short term statistic for a given metadata_id.

    Returns the id of the latest short term statistic for the metadata_id
    that was added to the cache, or None if no latest short term statistic
    was found for the metadata_id.
    """
    ...

@retryable_database_job("statistics")
def import_statistics(instance: Recorder, metadata: StatisticMetaData, statistics: Iterable[StatisticData], table: type[StatisticsBase]) -> bool:
    """Process an import_statistics job."""
    ...

@retryable_database_job("adjust_statistics")
def adjust_statistics(instance: Recorder, statistic_id: str, start_time: datetime, sum_adjustment: float, adjustment_unit: str) -> bool:
    """Process an add_statistics job."""
    ...

def change_statistics_unit(instance: Recorder, statistic_id: str, new_unit: str, old_unit: str) -> None:
    """Change statistics unit for a statistic_id."""
    ...

@callback
def async_change_statistics_unit(hass: HomeAssistant, statistic_id: str, *, new_unit_of_measurement: str, old_unit_of_measurement: str) -> None:
    """Change statistics unit for a statistic_id."""
    ...

def cleanup_statistics_timestamp_migration(instance: Recorder) -> bool:
    """Clean up the statistics migration from timestamp to datetime.

    Returns False if there are more rows to update.
    Returns True if all rows have been updated.
    """
    ...

