"""
This type stub file was generated by pyright.
"""

from collections.abc import Callable, Iterable
from dataclasses import dataclass
from typing import TYPE_CHECKING
from sqlalchemy.engine import Engine
from sqlalchemy.orm.session import Session
from homeassistant.core import HomeAssistant
from .const import SupportedDialect
from .util import retryable_database_job
from . import Recorder

"""Schema migration helpers."""
if TYPE_CHECKING:
    ...
LIVE_MIGRATION_MIN_SCHEMA_VERSION = ...
_EMPTY_ENTITY_ID = ...
_EMPTY_EVENT_TYPE = ...
_LOGGER = ...
@dataclass
class _ColumnTypesForDialect:
    big_int_type: str
    timestamp_type: str
    context_bin_type: str
    ...


_MYSQL_COLUMN_TYPES = ...
_POSTGRESQL_COLUMN_TYPES = ...
_SQLITE_COLUMN_TYPES = ...
_COLUMN_TYPES_FOR_DIALECT: dict[SupportedDialect | None, _ColumnTypesForDialect] = ...
def raise_if_exception_missing_str(ex: Exception, match_substrs: Iterable[str]) -> None:
    """Raise if the exception and cause do not contain the match substrs."""
    ...

def get_schema_version(session_maker: Callable[[], Session]) -> int | None:
    """Get the schema version."""
    ...

@dataclass
class SchemaValidationStatus:
    """Store schema validation status."""
    current_version: int
    schema_errors: set[str]
    valid: bool
    ...


def validate_db_schema(hass: HomeAssistant, instance: Recorder, session_maker: Callable[[], Session]) -> SchemaValidationStatus | None:
    """Check if the schema is valid.

    This checks that the schema is the current version as well as for some common schema
    errors caused by manual migration between database engines, for example importing an
    SQLite database to MariaDB.
    """
    ...

def live_migration(schema_status: SchemaValidationStatus) -> bool:
    """Check if live migration is possible."""
    ...

def migrate_schema(instance: Recorder, hass: HomeAssistant, engine: Engine, session_maker: Callable[[], Session], schema_status: SchemaValidationStatus) -> None:
    """Check if the schema needs to be upgraded."""
    ...

def post_schema_migration(instance: Recorder, old_version: int, new_version: int) -> None:
    """Post schema migration.

    Run any housekeeping tasks after the schema migration has completed.

    Post schema migration is run after the schema migration has completed
    and the queue has been processed to ensure that we reduce the memory
    pressure since events are held in memory until the queue is processed
    which is blocked from being processed until the schema migration is
    complete.
    """
    ...

@retryable_database_job("migrate states context_ids to binary format")
def migrate_states_context_ids(instance: Recorder) -> bool:
    """Migrate states context_ids to use binary format."""
    ...

@retryable_database_job("migrate events context_ids to binary format")
def migrate_events_context_ids(instance: Recorder) -> bool:
    """Migrate events context_ids to use binary format."""
    ...

@retryable_database_job("migrate events event_types to event_type_ids")
def migrate_event_type_ids(instance: Recorder) -> bool:
    """Migrate event_type to event_type_ids."""
    ...

@retryable_database_job("migrate states entity_ids to states_meta")
def migrate_entity_ids(instance: Recorder) -> bool:
    """Migrate entity_ids to states_meta.

    We do this in two steps because we need the history queries to work
    while we are migrating.

    1. Link the states to the states_meta table
    2. Remove the entity_id column from the states table (in post_migrate_entity_ids)
    """
    ...

@retryable_database_job("post migrate states entity_ids to states_meta")
def post_migrate_entity_ids(instance: Recorder) -> bool:
    """Remove old entity_id strings from states.

    We cannot do this in migrate_entity_ids since the history queries
    still need to work while the migration is in progress.
    """
    ...

@retryable_database_job("cleanup_legacy_event_ids")
def cleanup_legacy_states_event_ids(instance: Recorder) -> bool:
    """Remove old event_id index from states.

    We used to link states to events using the event_id column but we no
    longer store state changed events in the events table.

    If all old states have been purged and existing states are in the new
    format we can drop the index since it can take up ~10MB per 1M rows.
    """
    ...

def initialize_database(session_maker: Callable[[], Session]) -> bool:
    """Initialize a new database."""
    ...

